{
    "model": "uncrtaints",
    "encoder_widths": [
        128
    ],
    "decoder_widths": [
        128,
        128,
        128,
        128,
        128
    ],
    "out_conv": [
        13
    ],
    "mean_nonLinearity": true,
    "var_nonLinearity": "softplus",
    "use_sar": true,
    "agg_mode": "att_group",
    "encoder_norm": "group",
    "decoder_norm": "batch",
    "n_head": 1,
    "d_model": 256,
    "use_v": false,
    "positional_encoding": true,
    "d_k": 4,
    "res_dir": "./results",
    "experiment_name": "monotemporalL2",
    "device": "cuda",
    "display_step": 10,
    "batch_size": 4,
    "lr": 0.001,
    "gamma": 0.8,
    "ref_date": "2014-04-03",
    "pad_value": 0,
    "padding_mode": "reflect",
    "val_every": 1,
    "val_after": 0,
    "pretrain": true,
    "input_t": 1,
    "sample_type": "pretrain",
    "vary_samples": true,
    "min_cov": 0.0,
    "max_cov": 1.0,
    "region": "all",
    "max_samples": 1000000000,
    "input_size": 256,
    "plot_every": -1,
    "loss": "l2",
    "covmode": "diag",
    "scale_by": 10.0,
    "separate_out": false,
    "resume_from": false,
    "epochs": 20,
    "trained_checkp": ""
}
